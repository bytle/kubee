#!/usr/bin/env bash


# shellcheck source=./bashlib-error.sh
source "bashlib-error.sh"
error::set_strict_mode
error::set_trap
# shellcheck source=./bashlib-echo.sh
source "bashlib-echo.sh"
# shellcheck source=./bashlib-doc.sh
source "bashlib-doc.sh"

post_alerts(){
  # Note on the post data
  # Labels (Identity) The labels of each alert are used to identify identical instances of an alert and to perform deduplication.
  # Annotation: The annotations are always set to those received most recently and are not identifying an alert.
  # The generatorURL field is a unique back-link which identifies the causing entity of this alert in the client.
    if [ "${1:-}" == "" ]; then
      doc::help synopsis
      echo::err "An alert name is mandatory"
      exit 1
    fi
    ALERT_NAME=$1
    SEVERITY=${2:-"critical"}
    echo::info "Signaling alert $ALERT_NAME to $API_URL_ENDPOINT"
    echo::debug "Curl Options: ${CURL_OPTIONS[*]}"

    # Rules:
    # * No space in name and value in labels and annotations otherwise we get `400000000`
    # * Should be minified otherwise we get `400`
    # * Both startsAt and endsAt timestamp are optional.
    #   If startsAt is omitted, the current time is assigned by the Alertmanager.
    #   endsAt is only set if the end time of an alert is known.
    #   Example:
    #   \"startsAt\": \"2024-11-18T18:59:03.316Z\",
    #   \"endsAt\": \"2024-11-19T18:59:03.316Z\",
    #
    # For debug: minimal working body is '[{"labels":{"alertname":"test"}}]'
    #
    # Labels are on what the route engine works
    # That's why the severity is a label
    BODY_NON_MINIFIED="[{
            \"labels\": {
                \"alertname\": \"$ALERT_NAME\",
                \"severity\":\"$SEVERITY\"
            },
            \"annotations\": {
                 \"summary\": \"high-latency\",
                 \"instance\": \"yolo.example.net\",
                 \"service\": \"my-service\"
            },
            \"generatorURL\": \"http://hostname-with-problem/path\"
    }]"
    if ! BODY=$(jq -rc . <<< $BODY_NON_MINIFIED); then
      echo::err "The body is not a valid json"
      echo::err "Body: ${BODY_NON_MINIFIED}"
      return 1
    fi
    echo::debug "Body: ${BODY}"
    # write-out add the http code as last line in the RESPONSE
    if ! RESPONSE=$(curl "${CURL_OPTIONS[@]}" --write-out '%{http_code}' $API_URL_ENDPOINT \
      --header "Content-Type: application/json" \
      --data $BODY); then
      HTTP_CODE=$(tail -n1 <<< "$RESPONSE")  # get the last line
      CONTENT=$(sed '$ d' <<< "$RESPONSE")   # get all but the last line which contains the status code
      if [ "$HTTP_CODE" != "200" ]; then
        echo::err "Bad response code of $HTTP_CODE"
        echo::echo "Content: "$CONTENT
        exit $HTTP_CODE
      fi
    fi
    echo::success "Alert $ALERT_NAME was signaled"
}
synopsis(){
  cat <<EOF
\`\`\`bash
$(basename "$0") [--url alert-manager-url] path method [name]
\`\`\`

where:
* \`path\` can be all [path apis](https://petstore.swagger.io/?url=https://raw.githubusercontent.com/prometheus/alertmanager/main/api/v2/openapi.yaml)
* \`method\` can be:
  * \`post\` - post (only for alerts)
  * \`get\`  - get (no filtering for now)
* \`name\` is a mandatory alert name to post a test alerts
* \`--url|-u\` defines the Alert Manager URL (\`http://localhost:9093\`), default to \`KUBEE_ALERT_MANAGER_URL\`

# Example
To trigger a test alert:
\`\`\`bash
$(basename "$0") alerts post test
\`\`\`
EOF
}

if [ "${1:-}" == "synopsis" ]; then
  synopsis
  exit
fi

args=$(getopt -l "url:help" -o "u:h" -- "$@")
# eval set to set the positional arguments back to $args
eval set -- "$args"

# API prefix to not fucked up the PATH variable
API_PATH=""
API_METHOD=""
ARGS=()
KUBEE_ALERT_MANAGER_URL=${KUBEE_ALERT_MANAGER_URL:-}
while [[ $# -gt 0 ]]; do
   case $1 in
    "--url"|"-u")
      shift
      KUBEE_ALERT_MANAGER_URL=$1
      shift
      ;;
    "--help"|"-h")
      doc::help synopsis
      exit
      ;;
    "--")
      shift
      ;;
    *)
      if [ "$API_PATH" = "" ]; then
        API_PATH="$1"
        shift
        continue;
      fi
      if [ "$API_METHOD" = "" ]; then
        API_METHOD="$1"
        shift
        continue;
      fi
      ARGS+=("$1")
      shift
      continue;
      ;;
    esac
done

if [ "$API_PATH" == "" ]; then
  doc::help synopsis
  echo::err "A path is mandatory"
  exit 1
fi

if [ "$KUBEE_ALERT_MANAGER_URL" == "" ]; then
  doc::help synopsis
  echo::err "The alert manager URL is mandatory"
  echo::err "Set it via the --url flag or the KUBEE_ALERT_MANAGER_URL env"
  exit 1
fi

case $API_PATH in
  "alerts"|"status"|"receivers"|"silences"|"alerts/groups")
    ;;
  silence*)
    ;;
  *)
    echo::err "The path $API_PATH is not supported"
    echo::err "See https://petstore.swagger.io/?url=https://raw.githubusercontent.com/prometheus/alertmanager/main/api/v2/openapi.yaml"
esac
API_URL_ENDPOINT="$KUBEE_ALERT_MANAGER_URL/api/v2/$API_PATH"


CURL_OPTIONS=()
# silence don't show progress bar
CURL_OPTIONS+=("-s")
# fail if any error
CURL_OPTIONS+=("--fail")

# Auth
if [ "${KUBEE_ALERT_MANAGER_BASIC_AUTH_PASS_USER:-}" != "" ]; then
  if ALERT_MANAGER_USER=$(pass $KUBEE_ALERT_MANAGER_BASIC_AUTH_PASS_USER); then
    if [ "${KUBEE_ALERT_MANAGER_BASIC_AUTH_PASS_PASSWORD:-}" == "" ]; then
      echo::err "The basic auth password env KUBEE_ALERT_MANAGER_BASIC_AUTH_PASS_PASSWORD is not set or empty"
      echo::err "The value is mandatory because the basic auth user env KUBEE_ALERT_MANAGER_BASIC_AUTH_PASS_USER"
      exit 1
    fi
    ALERT_MANAGER_PASSWORD=$(pass $KUBEE_ALERT_MANAGER_BASIC_AUTH_PASS_PASSWORD)
    CURL_OPTIONS+=("--user" "$ALERT_MANAGER_USER:$ALERT_MANAGER_PASSWORD")
  fi
fi

case $API_METHOD in
  "post")
    CURL_OPTIONS+=("-XPOST")
    case $API_PATH in
      "alerts")
        post_alerts "${ARGS[@]}"
        ;;
      *)
        echo::err "Post on $API_PATH is not yet supported"
        exit 1
        ;;
    esac
    ;;
  "get")
    CURL_OPTIONS+=("-XGET")
    curl "${CURL_OPTIONS[@]}" $API_URL_ENDPOINT # | jq '{ alertname: .[].labels.alertname, instance: .[].labels.instance }'
    ;;
  "check")
    # we could check the `status` property of the `alertmanager` CRD
    # ie https://kube.i.eraldy.com/#/customresourcedefinition/alertmanagers.monitoring.coreos.com/kube-prometheus/alertmanager?namespace=kube-prometheus
    # Example where you see the reconciliation time and an error if the status is not true
    # status:
    #  conditions:
    #    - lastTransitionTime: '2024-11-19T11:14:36Z'
    #      message: ''
    #      observedGeneration: 8
    #      reason: ''
    #      status: 'True'
    #      type: Available
    #    - lastTransitionTime: '2024-11-20T15:08:19Z'
    #      message: ''
    #      observedGeneration: 8
    #      reason: ''
    #      status: 'True'
    #      type: Reconciled

    # Event also
    # AlertmanagerConfig opsgenie was rejected due to invalid configuration: root route must define a receiver
    ;;
  *)
    doc::help synopsis
    echo::err "The method $API_METHOD is unknown"
    exit 1
esac
